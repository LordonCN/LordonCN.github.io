---
layout: post
title: "深度学习初探"
subtitle: 'PG，PG_DQN,DDPG'
author: "Lordon"
header-img: img/jassica/jessica-jung-celebrity.jpg
catalog: true
tags:
  - PG
  - Tensorflow
---
# 0、总体流程
> Q-learning与DQN

通过当前`observation`与下一步`obs_`获得两个预测值`V`来选择`Action`，当然这个缺点很明显：可视野很小。<br>
> Policy Gradients

通过不断地对`每一回合`各参数的的决策记录来进行`复盘`学习，当然这样效果是显而易见的，运算速度相对来说会变得慢。<br>
所以呢，两种方式结合一下得到类似于Actor-Critic的网络结构，把actor作为`执行机构`，critic作为`判断机构`能够给予执行机构指引，一个似眼，一个像腿。
<img src="/img/191026image/ddpgliuchengtu.jpg" >

# 1、DQN
QLearning是reninforcement learning中value-based的方法。Q即为Q（s,a），是在某一时刻的 `s`tate 下(s∈S)，采取 动作`a`ction (a∈A)获得收益的期望，环境会根据agent的动作反馈相应的回报`r`eward，所以算法的主要思想就是将`State`与`Action`构建成一张Q-table来存储Q值，然后根据Q值来选取能够获得最大的收益的动作。


# 2、Policy Gradients
>策略梯度决策





